{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as skl\n",
    "import pandas as pd\n",
    "\n",
    "features = pd.read_csv(\"data/features.csv\", index_col=\"POINT_ID\")\n",
    "results = pd.read_csv(\"data/results.csv\", index_col=\"POINT_ID\")\n",
    "\n",
    "# Split data into train (90%) and test set (10%)\n",
    "X_train, X_test, y_train, y_test = skl.model_selection.train_test_split(features, results, test_size=0.1, random_state=235)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vahid\\OneDrive\\Desktop\\Ati-khare\\.venv\\Lib\\site-packages\\sklearn\\base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the Random Forest model\n",
    "rf = skl.ensemble.RandomForestRegressor(random_state=972)\n",
    "\n",
    "# Define the parameter grid for grid search\n",
    "param_grid = {\n",
    "    'n_estimators': range(11, 29, 3),   # Number of trees in the forest\n",
    "    'max_depth': range(5, 26, 4),       # Maximum depth of the trees\n",
    "    'min_samples_split': [2, 3, 5],     # Minimum samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 4, 6],   # Minimum samples required to be at a leaf node\n",
    "    'max_features': ['sqrt', 'log2'],   # Number of features to consider when splitting a node\n",
    "    'bootstrap': [True, False]          # Whether bootstrap samples are used when building trees\n",
    "}\n",
    "\n",
    "# Setup the GridSearchCV\n",
    "grid_search = skl.model_selection.GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, n_jobs=-1, scoring='r2')\n",
    "\n",
    "# Fit GridSearchCV to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Predict using the best model\n",
    "best_rf = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'bootstrap': False, 'max_depth': 17, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 26}\n"
     ]
    }
   ],
   "source": [
    "# Print the best parameters found by GridSearchCV\n",
    "print(\"Best parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best r2 score: 0.24\n"
     ]
    }
   ],
   "source": [
    "print(\"Best r2 score:\", round(grid_search.best_score_,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30717843766121933"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = best_rf.predict(X_test)\n",
    "\n",
    "skl.metrics.r2_score(y_true=y_test, y_pred=y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
